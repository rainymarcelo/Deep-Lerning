{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUiqOjXpGv0X",
        "outputId": "6120874d-59d6-4893-ec1c-fe94e1aabaad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting visualkeras\n",
            "  Downloading visualkeras-0.0.2-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from visualkeras) (9.4.0)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.10/dist-packages (from visualkeras) (1.23.5)\n",
            "Collecting aggdraw>=1.3.11 (from visualkeras)\n",
            "  Downloading aggdraw-1.3.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (993 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m993.7/993.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: aggdraw, visualkeras\n",
            "Successfully installed aggdraw-1.3.18 visualkeras-0.0.2\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, BatchNormalization, Input, MaxPooling2D, Activation\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import shutil\n",
        "import os\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from google.colab import files\n",
        "from PIL import Image, ImageOps\n",
        "from numpy import asarray\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "import gdown\n",
        "import numpy as np\n",
        "from keras import backend as K\n",
        "!pip install visualkeras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XcaV8NgWBqK"
      },
      "source": [
        "# Cargar el dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHZs5REXf52p",
        "outputId": "6faa6e00-4f23-44ce-a3bf-0e17bee8dfd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=14QSH1n3VKeLaM7JUhONV8PHOd61xG6PB\n",
            "To: /content/kaggle.json\n",
            "100% 76.0/76.0 [00:00<00:00, 327kB/s]\n"
          ]
        }
      ],
      "source": [
        "import gdown\n",
        "\n",
        "# Definir la URL de Google Drive del archivo\n",
        "file_url = \"14QSH1n3VKeLaM7JUhONV8PHOd61xG6PB\"\n",
        "\n",
        "# Especificar el nombre del archivo\n",
        "file_name = \"kaggle.json\"\n",
        "\n",
        "# Descargar el archivo desde Google Drive\n",
        "!gdown --id {file_url} -O {file_name}\n",
        "\n",
        "# Mover el archivo a la ubicación específica\n",
        "!mkdir -p ~/.kaggle/ && mv {file_name} ~/.kaggle/ && chmod 600 ~/.kaggle/{file_name}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmXrP6SaiVtF"
      },
      "source": [
        "**Usar este metodo solo si el anterior no funciono**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0fqL0ZDrI-m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48ba8ea1-6acf-4230-da62-8cb08fbd04b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading vehicle.zip to /content\n",
            "100% 6.87G/6.88G [01:08<00:00, 124MB/s]\n",
            "100% 6.88G/6.88G [01:08<00:00, 108MB/s]\n"
          ]
        }
      ],
      "source": [
        "#Download kaggle dataset\n",
        "!kaggle competitions download -c vehicle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "F6eKUBWDrJle",
        "outputId": "51091d8a-c58f-41d2-f64c-5dab581d91e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "replace ./dataset/train/train/Bus/000001_02.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "#Unzip kaggle Datset\n",
        "!unzip vehicle '*/*/Car/*' '*/*/Motorcycle/*' '*/*/Truck/*' '*/*/Bus/*' -d \"./dataset\" > ./.logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htSb7maix79h"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Ruta del directorio donde se extrajo el dataset\n",
        "ruta_directorio = \"/content/\"\n",
        "\n",
        "# Función para calcular el tamaño de un directorio\n",
        "def obtener_tamano_directorio(ruta):\n",
        "    total_tamano = 0\n",
        "    for dirpath, dirnames, filenames in os.walk(ruta):\n",
        "        for f in filenames:\n",
        "            fp = os.path.join(dirpath, f)\n",
        "            total_tamano += os.path.getsize(fp)\n",
        "    return total_tamano\n",
        "\n",
        "# Obtener el tamaño del directorio\n",
        "tamano_descomprimido = obtener_tamano_directorio(ruta_directorio)\n",
        "\n",
        "# Convertir el tamaño a GB para mayor claridad\n",
        "tamano_descomprimido_gb = tamano_descomprimido / (1024**3)\n",
        "\n",
        "print(f\"El tamaño del archivo descomprimido es aproximadamente {tamano_descomprimido_gb:.2f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qVPcu0aWMqB"
      },
      "source": [
        "# Prepocesado de los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8XcGmGAF9CZ"
      },
      "outputs": [],
      "source": [
        "classes = ['Bus', 'Car', 'Motorcycle', 'Truck']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAt3PPxgbCHg"
      },
      "outputs": [],
      "source": [
        "#Showing radom images from each class in dataset\n",
        "plt.figure(figsize=(12,12))\n",
        "count = 0\n",
        "for i, cls in enumerate(classes):\n",
        "  for j in range(5):\n",
        "    dir = f'/content/dataset/train/train/{cls}'\n",
        "    filename = random.choice(os.listdir(dir))\n",
        "    path = os.path.join(dir, filename)\n",
        "    img = plt.imread(path)\n",
        "    count += 1\n",
        "    plt.subplot(5,5,count)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(img)\n",
        "    plt.xlabel(f'{cls}\\n ({img.shape[0]}x{img.shape[1]})')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9r3ciMTHWbwz"
      },
      "source": [
        "**Dividir los datos en los de test y validacion**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TH6cewaKtfyh"
      },
      "outputs": [],
      "source": [
        "#Load and transform images in tensorflow\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    validation_split=0.2,\n",
        "    rescale=1./255,\n",
        "  )\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    '/content/dataset/train/train',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=64,seed=123,\n",
        "    subset='training',\n",
        "    color_mode=\"rgb\",\n",
        "    class_mode='sparse',\n",
        ")\n",
        "valid_generator = datagen.flow_from_directory(\n",
        "    '/content/dataset/train/train',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=64,seed=123,\n",
        "    subset='validation',\n",
        "    class_mode='sparse',\n",
        "    color_mode=\"rgb\",\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gwUzJ0NjqOg"
      },
      "outputs": [],
      "source": [
        "labels_frec = {i:0 for i in classes}\n",
        "labels = {cls:i for cls,i in enumerate(classes)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kwrp0sfeXJtA"
      },
      "source": [
        "**Cantida de imagenes por clase**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7usuqkBfok_M"
      },
      "outputs": [],
      "source": [
        "for i in train_generator.labels:\n",
        "  labels_frec[labels[int(i)]] = labels_frec[labels[int(i)]] +1\n",
        "train_class_frec = labels_frec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ef-SZkHzDJYd"
      },
      "outputs": [],
      "source": [
        "train_classes = [labels[int(i)] for i in train_generator.labels]\n",
        "np.unique(train_classes, return_counts=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TiFYD0a9o0k_"
      },
      "outputs": [],
      "source": [
        "for i in valid_generator.labels:\n",
        "    labels_frec[labels[int(i)]] = labels_frec[labels[int(i)]] +1\n",
        "labels_frec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7w9lYtJFp3an"
      },
      "outputs": [],
      "source": [
        "plt.bar(labels_frec.keys(), labels_frec.values(), color ='green',width = 0.6)\n",
        "plt.xlabel(\"Classes\")\n",
        "plt.ylabel(\"frecunecy\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-i6RMq-mvE3m"
      },
      "outputs": [],
      "source": [
        "#showing images after transformations\n",
        "\n",
        "import numpy as np\n",
        "fig = plt.figure(figsize=(20,10))\n",
        "imgs,lbls = train_generator.next()\n",
        "for i in range(0,32):\n",
        "  plt.subplot(4,8,i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  plt.imshow(imgs[i].reshape((224,224, 3)), cmap='gray')\n",
        "  plt.xlabel(classes[int(lbls[i])])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62FugZMnF4kL"
      },
      "outputs": [],
      "source": [
        "#Compute Class weights\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "class_weight = compute_class_weight('balanced', classes=[0,1,2,3], y=valid_generator.labels.astype(int))\n",
        "class_weight = dict(zip(range(len(class_weight)), class_weight))\n",
        "class_weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNMfe9ssW8JP"
      },
      "source": [
        "**Se definen las metricas**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeUhE3vmYofD"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "# from sklearn.metrics import multilabel_confusion_matrix\n",
        "def conf_matrix_m(y_true, y_pred):\n",
        "  return tf.math.confusion_matrix(y_true, K.argmax(y_pred), num_classes=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSPUNEvNpENN"
      },
      "source": [
        "#Modelo CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZ4VohinXYeh"
      },
      "source": [
        "**Se crea el modelo CNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_Ieo2uakq-l"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = Sequential()\n",
        "\n",
        "#### Input Layer ####\n",
        "model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same',\n",
        "                 activation='relu', input_shape=(224, 224, 3)))\n",
        "\n",
        "#### Convolutional Layers ####\n",
        "model.add(Conv2D(32, (3,3), activation='relu'))\n",
        "model.add(MaxPooling2D((2,2)))  # Pooling\n",
        "model.add(Dropout(0.5)) # Dropout\n",
        "\n",
        "model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
        "model.add(Conv2D(64, (3,3), activation='relu'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
        "model.add(Conv2D(128, (3,3), activation='relu'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(512, (5,5), padding='same', activation='relu'))\n",
        "model.add(Conv2D(512, (5,5), activation='relu'))\n",
        "model.add(MaxPooling2D((4,4)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "#### Fully-Connected Layer ####\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "# model.summary()\n",
        "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              optimizer=\"Nadam\",\n",
        "              metrics=['accuracy', f1_m, conf_matrix_m, precision_m, recall_m ]\n",
        "              )\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fDc4gw4XfeV"
      },
      "source": [
        "**Se entrena el modelo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrRl8L04vrEh"
      },
      "outputs": [],
      "source": [
        "history =model.fit(train_generator,\n",
        "                    steps_per_epoch=len(train_generator),\n",
        "                    epochs=20,\n",
        "                    validation_data=valid_generator,\n",
        "                    validation_steps = len(valid_generator),\n",
        "                    class_weight=class_weight,\n",
        "                  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTdwuJm7Xj-B"
      },
      "source": [
        "**Se guarda el modelo(en .h5 y json)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mAhqjFysNmI"
      },
      "outputs": [],
      "source": [
        "model.save('my-model.h5',)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nCZLYmT8RrD"
      },
      "outputs": [],
      "source": [
        "model.save('my-model-h5', save_format='h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDCAdsYgfyfQ"
      },
      "outputs": [],
      "source": [
        "model.to_json()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drAeyMvlXvcC"
      },
      "source": [
        "**Se crea la matrix de confusion**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yh_ImSUmvwmH"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "\n",
        "y_pred = []\n",
        "y_true = []\n",
        "valid_generator.reset()\n",
        "for i in range(88):\n",
        "  x,y = valid_generator.next()\n",
        "  y_true += y.astype(int).tolist()\n",
        "  y_pred += list(np.argmax(model.predict(x), axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8x5JkCogVsk"
      },
      "outputs": [],
      "source": [
        "cm = tf.math.confusion_matrix(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0s1bS-qgZE3"
      },
      "outputs": [],
      "source": [
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "df_cm = pd.DataFrame(cm)\n",
        "df_cm= df_cm.astype(int)\n",
        "# df_cm = df_cm.reindex(classes)\n",
        "df_cm.index = classes\n",
        "df_cm.columns = classes\n",
        "df_cm\n",
        "\n",
        "sn.heatmap(df_cm, annot=True, fmt='d',)\n",
        "plt.ylabel('true class')\n",
        "plt.xlabel('predicted class')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVKQjN1mghrM"
      },
      "outputs": [],
      "source": [
        "np.unique(valid_generator.labels, return_counts=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4D-TzqXgkSk"
      },
      "outputs": [],
      "source": [
        "!pip3 install visualkeras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1S8uCFTX3M-"
      },
      "source": [
        "**Arquitectura del modelo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OU7hZtFrGndj"
      },
      "outputs": [],
      "source": [
        "#Visualize model architecture\n",
        "import visualkeras\n",
        "from PIL import ImageFont\n",
        "\n",
        "visualkeras.layered_view(model, legend=True, to_file='model-image.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHGgmdmDYnkj"
      },
      "source": [
        "**Accuracy del modelo a lo largo de las epocas**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trLKH1W2yh_K"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracies')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'test'], loc='best')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2N9vxUDYwIp"
      },
      "source": [
        "**Loss del modelo a lo largo de las epocas**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpWgizgvyn6D"
      },
      "outputs": [],
      "source": [
        "#showing loss over epochs\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'test'], loc='best')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vjyt9BmyvJC"
      },
      "outputs": [],
      "source": [
        "# prediction= model.predict(valid_generator,batch_size=32, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rJgFAidVKqX"
      },
      "outputs": [],
      "source": [
        "eval = model.evaluate(valid_generator)\n",
        "eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3LV_SxVfE_E"
      },
      "outputs": [],
      "source": [
        "eval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IT7_aYtTY6I5"
      },
      "source": [
        "**Prueba del modelo usando imagenes de validacion**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOUSbqYFgzM7"
      },
      "outputs": [],
      "source": [
        "x = valid_generator.next()\n",
        "\n",
        "offset = 5\n",
        "fig = plt.figure(figsize=(25,10))\n",
        "for i in range(8):\n",
        "  plt.subplot(1,8,i+1)\n",
        "  img = valid_generator[0][0][i+offset]\n",
        "  plt.imshow(img.reshape(224,224,3))\n",
        "  img = np.expand_dims(img, axis=0)\n",
        "  pred = model.predict(img)[0]\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.title(classes[int(valid_generator[0][1][i+offset])])\n",
        "\n",
        "fig = plt.figure(figsize=(25,4))\n",
        "for i in range(8):\n",
        "  plt.subplot(1,8,i+1)\n",
        "  img = valid_generator[0][0][i+offset]\n",
        "  img = np.expand_dims(img, axis=0)\n",
        "  pred = model.predict(img)[0]\n",
        "  prob = {i:j for i,j in zip(classes,list(pred))}\n",
        "  plt.bar(prob.keys(), prob.values())\n",
        "  plt.xticks(rotation='vertical')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJS_IkA5g2h3"
      },
      "outputs": [],
      "source": [
        "from PIL import Image, ImageOps\n",
        "from numpy import asarray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EpBRnF__dP8e"
      },
      "outputs": [],
      "source": [
        "valid_generator.next()[0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5UQMUuijKEq"
      },
      "source": [
        "#Segundo Modelo CNN 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eF-mWMisarfO"
      },
      "source": [
        "**Se crea el segundo modelo CNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nU9TewLMm1vA"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# New CNN model\n",
        "model2 = models.Sequential()\n",
        "\n",
        "# Input Layer\n",
        "model2.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
        "model2.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Convolutional Layers\n",
        "model2.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model2.add(layers.MaxPooling2D((2, 2)))\n",
        "model2.add(layers.BatchNormalization())\n",
        "model2.add(layers.Dropout(0.3))\n",
        "\n",
        "model2.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
        "model2.add(layers.MaxPooling2D((2, 2)))\n",
        "model2.add(layers.BatchNormalization())\n",
        "model2.add(layers.Dropout(0.3))\n",
        "\n",
        "# Fully-Connected Layer\n",
        "model2.add(layers.Flatten())\n",
        "model2.add(layers.Dense(512, activation='relu'))\n",
        "model2.add(layers.Dropout(0.5))\n",
        "model2.add(layers.Dense(4, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model2.compile(loss='sparse_categorical_crossentropy',\n",
        "               optimizer='adam',\n",
        "               metrics=['accuracy', f1_m, conf_matrix_m, precision_m, recall_m])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSiXNu7SavwA"
      },
      "source": [
        "**Se entrena el modelo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d8NDRLvnFCE"
      },
      "outputs": [],
      "source": [
        "#Train the model\n",
        "history =model2.fit(train_generator,\n",
        "                    steps_per_epoch=len(train_generator),\n",
        "                    epochs=20,\n",
        "                    validation_data=valid_generator,\n",
        "                    validation_steps = len(valid_generator),\n",
        "                    class_weight=class_weight,\n",
        "                  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unYoLjrzaykx"
      },
      "source": [
        "**Se guarda el modelo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCRpRi2UnbQC"
      },
      "outputs": [],
      "source": [
        "model2.save('my-model2.h5',)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GB7sCk-Nnkc-"
      },
      "outputs": [],
      "source": [
        "model2.save('my-model2-h5', save_format='h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Er2RL5HYnmFh"
      },
      "outputs": [],
      "source": [
        "model2.to_json()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGLWLKVBa27-"
      },
      "source": [
        "**Se visualiza la arquitectura**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pivXFhgXnqX7"
      },
      "outputs": [],
      "source": [
        "#Visualize model2 architecture\n",
        "import visualkeras\n",
        "from PIL import ImageFont\n",
        "\n",
        "visualkeras.layered_view(model2, legend=True, to_file='model2-image.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzUTFUVhu_u7"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "\n",
        "y_pred = []\n",
        "y_true = []\n",
        "valid_generator.reset()\n",
        "for i in range(88):\n",
        "  x,y = valid_generator.next()\n",
        "  y_true += y.astype(int).tolist()\n",
        "  y_pred += list(np.argmax(model2.predict(x), axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Z_z6btkvDXc"
      },
      "outputs": [],
      "source": [
        "cm = tf.math.confusion_matrix(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeA22C0LvM8a"
      },
      "outputs": [],
      "source": [
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "df_cm = pd.DataFrame(cm)\n",
        "df_cm= df_cm.astype(int)\n",
        "# df_cm = df_cm.reindex(classes)\n",
        "df_cm.index = classes\n",
        "df_cm.columns = classes\n",
        "df_cm\n",
        "\n",
        "sn.heatmap(df_cm, annot=True, fmt='d',)\n",
        "plt.ylabel('true class')\n",
        "plt.xlabel('predicted class')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KkBuva7a72x"
      },
      "source": [
        "**Accuracy del modelo a lo largo de las epocas**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrnCGpl3n9Qj"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracies')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'test'], loc='best')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gud0h318bICm"
      },
      "source": [
        "**loss del modelo a lo largo de las epocas**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uv98M8i7oKaL"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'test'], loc='best')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqX3N85LoQVf"
      },
      "outputs": [],
      "source": [
        "eval = model2.evaluate(valid_generator)\n",
        "eval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "464emHeXbMSQ"
      },
      "source": [
        "**Se evalua el modelo usando imagenes de validacion**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hiGlt3FBoRPL"
      },
      "outputs": [],
      "source": [
        "#Show some images and its prediction\n",
        "x = valid_generator.next()\n",
        "\n",
        "offset = 5\n",
        "fig = plt.figure(figsize=(25,10))\n",
        "for i in range(8):\n",
        "  plt.subplot(1,8,i+1)\n",
        "  img = valid_generator[0][0][i+offset]\n",
        "  plt.imshow(img.reshape(224,224,3))\n",
        "  img = np.expand_dims(img, axis=0)\n",
        "  pred = model2.predict(img)[0]\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.title(classes[int(valid_generator[0][1][i+offset])])\n",
        "\n",
        "fig = plt.figure(figsize=(25,4))\n",
        "for i in range(8):\n",
        "  plt.subplot(1,8,i+1)\n",
        "  img = valid_generator[0][0][i+offset]\n",
        "  img = np.expand_dims(img, axis=0)\n",
        "  pred = model2.predict(img)[0]\n",
        "  prob = {i:j for i,j in zip(classes,list(pred))}\n",
        "  plt.bar(prob.keys(), prob.values())\n",
        "  plt.xticks(rotation='vertical')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H069HzLnp4ck"
      },
      "source": [
        "#Transfer learning with pretrained VGG16 model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U-CgjpObpm9"
      },
      "source": [
        "**Se usa el VGG16 para probar como funciona y ver como se desempeña en comparacion con los modelos propios**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdiNAbgwl3U7"
      },
      "outputs": [],
      "source": [
        "image_input = Input(shape=(224, 224, 3))\n",
        "\n",
        "model2 = VGG16(input_tensor=image_input, include_top=True,weights='imagenet')\n",
        "\n",
        "\n",
        "last_layer = model2.get_layer('block5_pool').output\n",
        "x= Flatten(name='flatten')(last_layer)\n",
        "x = Dense(128, activation='relu', name='fc1')(x)\n",
        "x = Dense(128, activation='relu', name='fc2')(x)\n",
        "out = Dense(len(classes), activation='softmax', name='output')(x)\n",
        "custom_model = Model(image_input, out)\n",
        "\n",
        "# freeze all the layers except the dense layers\n",
        "for layer in custom_model.layers[:-3]:\n",
        "\tlayer.trainable = False\n",
        "\n",
        "custom_model.summary()\n",
        "\n",
        "custom_model.compile(\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    optimizer='adadelta',\n",
        "    metrics=['accuracy', f1_m, conf_matrix_m, precision_m, recall_m ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4MCkG18M8sQ"
      },
      "outputs": [],
      "source": [
        "vgg16_history = custom_model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    epochs=20,\n",
        "    validation_data=valid_generator,\n",
        "    validation_steps = len(valid_generator),\n",
        "    class_weight=class_weight,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9asGI-FmqGTH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udU9kbtkqkeK"
      },
      "outputs": [],
      "source": [
        "custom_model.save('my-vgg16-model.h5',)\n",
        "!zip -r my-vgg16-model.zip my-vgg16-model.h5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSM9fugoqkeM"
      },
      "outputs": [],
      "source": [
        "custom_model.save('my-model-h5', save_format='h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JNZZtPiqkeN"
      },
      "outputs": [],
      "source": [
        "custom_model.to_json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2clbXiPlqkeO"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "\n",
        "y_pred = []\n",
        "y_true = []\n",
        "valid_generator.reset()\n",
        "for i in range(88):\n",
        "  x,y = valid_generator.next()\n",
        "  y_true += y.astype(int).tolist()\n",
        "  y_pred += list(np.argmax(custom_model.predict(x), axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULjAmrL8qkeO"
      },
      "outputs": [],
      "source": [
        "vgg16_cm = tf.math.confusion_matrix(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dleZt1baqkeP"
      },
      "outputs": [],
      "source": [
        "#Confusion matrix\n",
        "\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "df_cm = pd.DataFrame(vgg16_cm)\n",
        "df_cm= df_cm.astype(int)\n",
        "# df_cm = df_cm.reindex(classes)\n",
        "df_cm.index = classes\n",
        "df_cm.columns = classes\n",
        "df_cm\n",
        "\n",
        "sn.heatmap(df_cm, annot=True, fmt='d',)\n",
        "plt.ylabel('true class')\n",
        "plt.xlabel('predicted class')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amBu7PSKqkeQ"
      },
      "outputs": [],
      "source": [
        "!pip3 install visualkeras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkswzMRJqkeR"
      },
      "outputs": [],
      "source": [
        "#Visualize model architecture\n",
        "import visualkeras\n",
        "from PIL import ImageFont\n",
        "\n",
        "visualkeras.layered_view(custom_model, legend=True, to_file='model-image.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlyHPryzqkeS"
      },
      "outputs": [],
      "source": [
        "#showing accuracy over epochs\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(vgg16_history.history['accuracy'])\n",
        "plt.plot(vgg16_history.history['val_accuracy'])\n",
        "plt.title('Model Accuracies')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'test'], loc='best')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YT8QK810qkeT"
      },
      "outputs": [],
      "source": [
        "#showing loss over epochs\n",
        "\n",
        "plt.plot(vgg16_history.history['loss'])\n",
        "plt.plot(vgg16_history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'test'], loc='best')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JI_akQBLqkeU"
      },
      "outputs": [],
      "source": [
        "eval = custom_model.evaluate(valid_generator)\n",
        "eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8eQWZ3UaqkeV"
      },
      "outputs": [],
      "source": [
        "#x = valid_generator.next()\n",
        "valid_generator.next()\n",
        "valid_generator.next()\n",
        "\n",
        "offset = 0\n",
        "fig = plt.figure(figsize=(25,10))\n",
        "for i in range(8):\n",
        "  plt.subplot(1,8,i+1)\n",
        "  img = valid_generator[0][0][i+offset]\n",
        "  plt.imshow(img.reshape(224,224,3))\n",
        "  img = np.expand_dims(img, axis=0)\n",
        "  pred = custom_model.predict(img)[0]\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.title(classes[int(valid_generator[0][1][i+offset])])\n",
        "\n",
        "fig = plt.figure(figsize=(25,4))\n",
        "for i in range(8):\n",
        "  plt.subplot(1,8,i+1)\n",
        "  img = valid_generator[0][0][i+offset]\n",
        "  img = np.expand_dims(img, axis=0)\n",
        "  pred = custom_model.predict(img)[0]\n",
        "  prob = {i:j for i,j in zip(classes,list(pred))}\n",
        "  plt.bar(prob.keys(), prob.values())\n",
        "  plt.xticks(rotation='vertical')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nZyNgqIaz2f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}